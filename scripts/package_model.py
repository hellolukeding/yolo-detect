"""
YOLO æ¨¡å‹è·¨å¹³å°è¿ç§»å·¥å…·
ç”¨äºæ‰“åŒ…æ¨¡å‹åŠç›¸å…³æ–‡ä»¶ï¼Œä¾¿äºåœ¨ä¸åŒå¹³å°é—´è¿ç§»
"""

import argparse
import json
import shutil
import sys
from datetime import datetime
from pathlib import Path

import torch
from ultralytics import YOLO


def get_model_info(model_path: str):
    """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
    try:
        model = YOLO(model_path)
        checkpoint = torch.load(model_path, map_location='cpu')

        info = {
            "model_path": str(model_path),
            "model_name": Path(model_path).name,
            "model_size_mb": Path(model_path).stat().st_size / (1024 * 1024),
            "model_type": model.model_name if hasattr(model, 'model_name') else "YOLO11",
            "classes": model.names,
            "num_classes": len(model.names),
            "pytorch_version": checkpoint.get('pytorch_version', 'unknown'),
            "ultralytics_version": checkpoint.get('version', 'unknown'),
            "training_date": checkpoint.get('date', 'unknown'),
            "epochs_trained": checkpoint.get('epoch', 'unknown'),
        }

        return info
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ¨¡å‹ä¿¡æ¯: {e}")
        return None


def validate_model(model_path: str):
    """éªŒè¯æ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸åŠ è½½"""
    try:
        print(f"éªŒè¯æ¨¡å‹: {model_path}")
        model = YOLO(model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"   ç±»åˆ«æ•°é‡: {len(model.names)}")
        print(f"   ç±»åˆ«: {model.names}")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return False


def package_model(
    model_path: str,
    output_dir: str = None,
    include_training_results: bool = True,
    include_dataset_config: bool = True
):
    """
    æ‰“åŒ…æ¨¡å‹åŠç›¸å…³æ–‡ä»¶

    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        include_training_results: æ˜¯å¦åŒ…å«è®­ç»ƒç»“æœå›¾è¡¨
        include_dataset_config: æ˜¯å¦åŒ…å«æ•°æ®é›†é…ç½®
    """
    model_path = Path(model_path)

    if not model_path.exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None

    # éªŒè¯æ¨¡å‹
    if not validate_model(str(model_path)):
        return None

    # åˆ›å»ºè¾“å‡ºç›®å½•
    if output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"model_package_{timestamp}"

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ“¦ å¼€å§‹æ‰“åŒ…æ¨¡å‹...")
    print(f"   è¾“å‡ºç›®å½•: {output_path.absolute()}")

    # 1. å¤åˆ¶æ¨¡å‹æ–‡ä»¶
    print("\n1ï¸âƒ£  å¤åˆ¶æ¨¡å‹æ–‡ä»¶...")
    model_dest = output_path / model_path.name
    shutil.copy2(model_path, model_dest)
    print(f"   âœ… {model_path.name}")

    # 2. è·å–å¹¶ä¿å­˜æ¨¡å‹ä¿¡æ¯
    print("\n2ï¸âƒ£  ä¿å­˜æ¨¡å‹ä¿¡æ¯...")
    model_info = get_model_info(str(model_path))
    if model_info:
        info_path = output_path / "model_info.json"
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, indent=2, ensure_ascii=False)
        print(f"   âœ… model_info.json")

    # 3. å¤åˆ¶è®­ç»ƒç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if include_training_results:
        print("\n3ï¸âƒ£  å¤åˆ¶è®­ç»ƒç»“æœ...")
        # å‡è®¾æ¨¡å‹åœ¨ runs/train/xxx/weights/best.pt
        if "runs/train" in str(model_path):
            training_dir = model_path.parent.parent

            # å¤åˆ¶ç»“æœå›¾è¡¨
            for img_file in training_dir.glob("*.jpg"):
                dest = output_path / "training_results" / img_file.name
                dest.parent.mkdir(exist_ok=True)
                shutil.copy2(img_file, dest)
                print(f"   âœ… {img_file.name}")

            # å¤åˆ¶ç»“æœ CSV
            results_csv = training_dir / "results.csv"
            if results_csv.exists():
                shutil.copy2(results_csv, output_path /
                             "training_results" / "results.csv")
                print(f"   âœ… results.csv")

            # å¤åˆ¶è®­ç»ƒå‚æ•°
            args_yaml = training_dir / "args.yaml"
            if args_yaml.exists():
                shutil.copy2(args_yaml, output_path / "args.yaml")
                print(f"   âœ… args.yaml")

    # 4. å¤åˆ¶æ•°æ®é›†é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if include_dataset_config:
        print("\n4ï¸âƒ£  æŸ¥æ‰¾æ•°æ®é›†é…ç½®...")
        dataset_configs = list(Path("configs").glob(
            "*.yaml")) if Path("configs").exists() else []
        if dataset_configs:
            for config in dataset_configs:
                dest = output_path / "configs" / config.name
                dest.parent.mkdir(exist_ok=True)
                shutil.copy2(config, dest)
                print(f"   âœ… {config.name}")

    # 5. åˆ›å»º requirements.txt
    print("\n5ï¸âƒ£  åˆ›å»ºä¾èµ–æ–‡ä»¶...")
    requirements = [
        f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"# PyTorch ç‰ˆæœ¬: {torch.__version__}",
        "",
        "ultralytics>=8.0.0",
        "torch>=2.0.0",
        "opencv-python>=4.8.0",
        "numpy>=1.24.0",
        "pillow>=10.0.0",
    ]

    req_path = output_path / "requirements.txt"
    with open(req_path, 'w') as f:
        f.write('\n'.join(requirements))
    print(f"   âœ… requirements.txt")

    # 6. åˆ›å»ºä½¿ç”¨è¯´æ˜
    print("\n6ï¸âƒ£  åˆ›å»ºä½¿ç”¨è¯´æ˜...")
    readme_content = f"""# YOLO æ¨¡å‹åŒ…

## ğŸ“¦ åŒ…å«å†…å®¹

- `{model_path.name}`: è®­ç»ƒå¥½çš„ YOLO æ¨¡å‹
- `model_info.json`: æ¨¡å‹è¯¦ç»†ä¿¡æ¯
- `requirements.txt`: Python ä¾èµ–
- `training_results/`: è®­ç»ƒç»“æœå›¾è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
- `configs/`: æ•°æ®é›†é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. åŠ è½½æ¨¡å‹

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO('{model_path.name}')

# è¿›è¡Œæ£€æµ‹
results = model('image.jpg')

# æ˜¾ç¤ºç»“æœ
results[0].show()
```

### 3. å‘½ä»¤è¡Œä½¿ç”¨

```bash
# å›¾åƒæ£€æµ‹
yolo predict model={model_path.name} source=image.jpg

# è§†é¢‘æ£€æµ‹
yolo predict model={model_path.name} source=video.mp4

# ç½‘ç»œæ‘„åƒå¤´
yolo predict model={model_path.name} source=0 show=True
```

## ğŸ“Š æ¨¡å‹ä¿¡æ¯

"""

    if model_info:
        readme_content += f"""
- **æ¨¡å‹ç±»å‹**: {model_info.get('model_type', 'YOLO')}
- **ç±»åˆ«æ•°é‡**: {model_info.get('num_classes', 'unknown')}
- **è®­ç»ƒè½®æ•°**: {model_info.get('epochs_trained', 'unknown')}
- **PyTorch ç‰ˆæœ¬**: {model_info.get('pytorch_version', 'unknown')}
- **æ¨¡å‹å¤§å°**: {model_info.get('model_size_mb', 0):.2f} MB

### æ£€æµ‹ç±»åˆ«

```python
{model_info.get('classes', {})}
```
"""

    readme_content += """

## ğŸ–¥ï¸ è·¨å¹³å°å…¼å®¹æ€§

æ­¤æ¨¡å‹å¯ä»¥åœ¨ä»¥ä¸‹å¹³å°ä½¿ç”¨ï¼š

- âœ… macOS (Apple Silicon / Intel)
- âœ… Linux (x86_64)
- âœ… Windows (x86_64)
- âœ… ARM è®¾å¤‡ (æ ‘è“æ´¾, Jetson Nano ç­‰)

### ä¸åŒå¹³å°çš„è®¾å¤‡é€‰æ‹©

```python
# macOS (Apple Silicon)
model.predict(source='image.jpg', device='mps')

# NVIDIA GPU
model.predict(source='image.jpg', device=0)  # or device='cuda'

# CPU
model.predict(source='image.jpg', device='cpu')
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. ç¡®ä¿ PyTorch å’Œ Ultralytics ç‰ˆæœ¬åŒ¹é…
2. æ ¹æ®ç›®æ ‡å¹³å°é€‰æ‹©åˆé€‚çš„ç¡¬ä»¶åŠ é€Ÿå‚æ•°
3. å¦‚éœ€æ›´å¥½çš„å…¼å®¹æ€§ï¼Œå¯ä»¥å¯¼å‡ºä¸º ONNX æ ¼å¼

```bash
yolo export model={model_path.name} format=onnx
```

---

æ‰“åŒ…æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

    readme_path = output_path / "README.md"
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    print(f"   âœ… README.md")

    # å®Œæˆ
    print("\n" + "=" * 60)
    print("âœ… æ¨¡å‹æ‰“åŒ…å®Œæˆ!")
    print("=" * 60)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_path.absolute()}")

    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    print(f"\nğŸ“‹ åŒ…å«æ–‡ä»¶:")
    for file in sorted(output_path.rglob("*")):
        if file.is_file():
            size_mb = file.stat().st_size / (1024 * 1024)
            print(
                f"   {str(file.relative_to(output_path)):40s} ({size_mb:.2f} MB)")

    # è®¡ç®—æ€»å¤§å°
    total_size = sum(
        f.stat().st_size for f in output_path.rglob("*") if f.is_file())
    print(f"\nğŸ’¾ æ€»å¤§å°: {total_size / (1024 * 1024):.2f} MB")

    # å‹ç¼©å»ºè®®
    print(f"\nğŸ’¡ å‹ç¼©æ‰“åŒ…:")
    print(f"   tar -czf {output_path.name}.tar.gz {output_path.name}")
    print(f"   æˆ–")
    print(f"   zip -r {output_path.name}.zip {output_path.name}")

    return output_path


def main():
    parser = argparse.ArgumentParser(
        description="YOLO æ¨¡å‹è·¨å¹³å°è¿ç§»æ‰“åŒ…å·¥å…·"
    )
    parser.add_argument(
        "model",
        type=str,
        help="æ¨¡å‹æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: runs/train/person_detection/weights/best.pt)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½• (é»˜è®¤: model_package_TIMESTAMP)"
    )
    parser.add_argument(
        "--no-training-results",
        action="store_true",
        help="ä¸åŒ…å«è®­ç»ƒç»“æœå›¾è¡¨"
    )
    parser.add_argument(
        "--no-dataset-config",
        action="store_true",
        help="ä¸åŒ…å«æ•°æ®é›†é…ç½®"
    )
    parser.add_argument(
        "--validate-only",
        action="store_true",
        help="ä»…éªŒè¯æ¨¡å‹ï¼Œä¸æ‰“åŒ…"
    )

    args = parser.parse_args()

    if args.validate_only:
        # ä»…éªŒè¯
        if validate_model(args.model):
            info = get_model_info(args.model)
            if info:
                print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
                for key, value in info.items():
                    print(f"   {key}: {value}")
            sys.exit(0)
        else:
            sys.exit(1)
    else:
        # æ‰“åŒ…
        result = package_model(
            model_path=args.model,
            output_dir=args.output,
            include_training_results=not args.no_training_results,
            include_dataset_config=not args.no_dataset_config
        )

        if result:
            sys.exit(0)
        else:
            sys.exit(1)


if __name__ == "__main__":
    main()
